allow_k8s_contexts(['orbstack', 'docker-desktop'])

load('ext://helm_remote', 'helm_remote')
load('ext://dotenv', 'dotenv')

is_prod = os.getenv('PROD') == 'true'

# Disable analytics in local development
os.putenv('NEXT_PUBLIC_ARCHESTRA_ANALYTICS', "disabled")

# set NEXT_PUBLIC_ARCHESTRA_API_BASE_URL to the same value as ARCHESTRA_API_BASE_URL
# so it's accessible by the frontend
api_base_url = os.getenv("ARCHESTRA_API_BASE_URL")
next_pubic_api_base_url = os.getenv("NEXT_PUBLIC_ARCHESTRA_API_BASE_URL")
if not next_pubic_api_base_url and api_base_url and api_base_url != "":
  os.putenv('NEXT_PUBLIC_ARCHESTRA_API_BASE_URL', api_base_url)


# Check if .env exists, if not copy from .env.example
if not os.path.exists('.env'):
  local('cp .env.example .env')
  print("üìù Created .env from .env.example, be sure to fill in any necessary unique values (ex. API keys)")
else:
  print("üìù .env already exists, skipping copy from .env.example")

# PostgreSQL database for local development
# https://dev.to/flodev/use-tilt-to-provide-easy-to-setup-development-environments-4n9d
helm_remote(
  'postgresql',
  repo_url='https://charts.bitnami.com/bitnami',
  namespace='archestra-dev',
  create_namespace=True,
  set=[
    'auth.database=archestra_dev',
    'auth.username=archestra',
    'auth.password=archestra_dev_password',

    # NOTE: Bitnami is archiving their image.. see these github comments for details
    # (this is essentially why we need to override image.repository and image.tag and global.security.allowInsecureImages)
    #
    # https://github.com/coder/coder/issues/19869#issuecomment-3305875979
    # https://github.com/bitnami/containers/issues/83267
    'image.repository=bitnamisecure/postgresql',
    'image.tag=latest',
    'global.security.allowInsecureImages=true'
  ]
)

k8s_resource('postgresql', port_forwards=['5432:5432'], labels=['database'])

# Jaeger for distributed tracing UI
helm_remote(
  'jaeger',
  repo_url='https://jaegertracing.github.io/helm-charts',
  namespace='archestra-dev',
  create_namespace=False,
  set=[
    'provisionDataStore.cassandra=false',
    'allInOne.enabled=true',
    'storage.type=memory',
    'agent.enabled=false',
    'collector.enabled=false',
    'query.enabled=false'
  ]
)

k8s_resource('jaeger', port_forwards=['16686:16686'], labels=['observability'])

# OpenTelemetry Collector
k8s_yaml(blob("""
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: archestra-dev
data:
  otel-collector-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318

    processors:
      batch:
        timeout: 10s
        send_batch_size: 1024

      resource:
        attributes:
          - key: deployment.environment
            value: development
            action: upsert

    exporters:
      otlp/jaeger:
        endpoint: jaeger-collector:4317
        tls:
          insecure: true

      debug:
        verbosity: detailed

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, resource]
          exporters: [otlp/jaeger, debug]
---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: archestra-dev
spec:
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  - name: otlp-http
    port: 4318
    targetPort: 4318
    protocol: TCP
  selector:
    app: otel-collector
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: archestra-dev
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        args:
          - "--config=/etc/otel-collector-config.yaml"
        volumeMounts:
        - name: config
          mountPath: /etc/otel-collector-config.yaml
          subPath: otel-collector-config.yaml
        ports:
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
"""
))

k8s_resource('otel-collector', port_forwards=['4317:4317', '4318:4318'], labels=['observability'])

# Database cleanup button (manual trigger only, for development)
local_resource(
  'db-clean',
  cmd='cd backend && pnpm db:clean',
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
  labels=['database']
)

dotenv(
  './.env'
)

local_resource(
  'pnpm-install',
  cmd='pnpm install',
  deps=['./frontend/package.json', './backend/package.json'],
  labels=['pre']
)

local_resource(
  'db-seed-mock-data',
  cmd='pnpm db:seed:mock-data',
  resource_deps=['pnpm-install', 'postgresql'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
  labels=['database']
)

local_resource(
  'db-migrate',
  # NOTE: we need to cd into the backend directory to run the migrate command
  # because otherwise if we run the command from this directory, it is run via turbo, which does not properly
  # propogate the required environment variables (ie. DATABASE_URL)
  # Retry logic: wait for PostgreSQL to be ready before running migrations, then seed
  cmd='''
    cd backend
    for i in {1..30}; do
      if pnpm db:migrate 2>/dev/null; then
        echo "‚úÖ Migration completed successfully"
        exit 0
      fi
      echo "‚è≥ Waiting for PostgreSQL... (attempt $i/30)"
      sleep 2
    done
    echo "‚ùå Migration failed after 30 attempts"
    exit 1
  ''',
  deps=['./backend/src/database/migrations'],
  resource_deps=['pnpm-install', 'postgresql'],
  labels=['database']
)

local_resource(
  'db-generate',
  cmd='cd backend && pnpm db:generate',
  resource_deps=['postgresql'],
  labels=['database'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)

# prod bundle
if is_prod:
  local_resource(
    'pnpm-prod',
    cmd='rm -rf frontend/.next && pnpm build',
    serve_cmd='pnpm start',
    labels=['prod'],
    resource_deps=['db-migrate']
  )

# dev
if not is_prod:
  local_resource(
    'pnpm-dev',
    serve_cmd='pnpm dev',
    labels=['dev'],
    resource_deps=['db-migrate']
  )

local_resource(
  'database-gui',
  # NOTE: we need to cd into the backend directory to run the migrate command
  # because otherwise if we run the command from this directory, it is run via turbo, which does not properly
  # propogate the required environment variables (ie. DATABASE_URL)
  serve_cmd='cd backend && pnpm db:studio',
  labels=['database'],
  resource_deps=['postgresql']
)

local_resource(
  'lint:fix',
  cmd='pnpm type-check && pnpm lint:fix',
  labels=['dev'],
  resource_deps=['pnpm-install'],
  deps=[
    "./frontend/src",
    "./backend/src",
    "./experiments/src",
    "./biome.json"
  ]
)

local_resource(
  'lint:fix:unsafe',
  cmd='pnpm lint:fix:unsafe',
  labels=['dev'],
  resource_deps=['pnpm-install'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)

local_resource(
  'codegen:api-client',
  cmd='pnpm codegen:api-client',
  labels=['dev'],
  resource_deps=['pnpm-install', 'pnpm-dev'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)

local_resource(
  'mcp-inspector',
  serve_env={
    'DANGEROUSLY_OMIT_AUTH': 'true'
  },
  serve_cmd='npx @modelcontextprotocol/inspector --server-url http://localhost:9000/v1/mcp',
  labels=['dev'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
)

local_resource(
  'unit-tests',
  cmd='pnpm test',
  labels=['test'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
  resource_deps=['pnpm-install', 'pnpm-dev']
)

local_resource(
  'e2e-tests',
  cmd='pnpm test:e2e',
  labels=['test'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
  resource_deps=['pnpm-install', 'pnpm-dev']
)

local_resource(
  'e2e-tests-ui',
  serve_cmd='pnpm test:e2e:ui',
  labels=['test'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False,
  resource_deps=['pnpm-install', 'pnpm-dev']
)

local_resource(
  'wiremock',
  serve_cmd='docker compose -f e2e-tests/docker-compose-platform.yml up wiremock',
  serve_dir='.',
  labels=['test'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False
)

local_resource(
  'n8n',
  serve_cmd='docker compose -f docker-compose-n8n.yml up n8n --no-deps',
  serve_dir='.',
  labels=['integrations'],
  trigger_mode=TRIGGER_MODE_MANUAL,
  auto_init=False
)
